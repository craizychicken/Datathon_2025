{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37daf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from datetime import date\n",
    "from tqdm import tqdm\n",
    "\n",
    "CSV_PATH = \"cleaned_climate_data.csv\"    # update path if needed\n",
    "FORECAST_YEAR = 2026\n",
    "FORECAST_WEEKS = list(range(1, 16))     # weeks 1..15\n",
    "LAGS = 4                                # number of lag weeks to use as features\n",
    "MIN_ROWS_TO_TRAIN = 52                  # minimum weekly rows to attempt training\n",
    "RANDOM_STATE = 42\n",
    "OUT_CSV = \"weather_forecast_2026.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24668541",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mounts: 100%|██████████| 7/7 [00:15<00:00,  2.26s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Helper: convert (year, iso_week) -> Monday date (ISO calendar)\n",
    "def iso_week_to_date(y, w):\n",
    "    try:\n",
    "        return date.fromisocalendar(int(y), int(w), 1)  # Monday of that ISO week\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# Load\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "required_cols = {\"mount_id\", \"Year\", \"week\", \"max_temp\", \"min_temp\", \"rain\"}\n",
    "if not required_cols.issubset(df.columns):\n",
    "    raise ValueError(f\"Input CSV must contain columns: {required_cols}\")\n",
    "\n",
    "# Build date column (Monday of ISO week)\n",
    "df[\"date\"] = df.apply(lambda r: iso_week_to_date(r[\"Year\"], r[\"week\"]), axis=1)\n",
    "df = df.dropna(subset=[\"date\"]).copy()\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "# Sort\n",
    "df = df.sort_values([\"mount_id\", \"date\"]).reset_index(drop=True)\n",
    "\n",
    "# Precompute historical weekly means per mount_id+week (for fallback)\n",
    "hist_week_mean = df.groupby([\"mount_id\", \"week\"])[[\"max_temp\",\"min_temp\",\"rain\"]].mean().reset_index()\n",
    "\n",
    "# Per-mount forecasting\n",
    "mount_ids = df[\"mount_id\"].unique().tolist()\n",
    "targets = [\"max_temp\", \"min_temp\", \"rain\"]\n",
    "\n",
    "results = []\n",
    "\n",
    "for mid in tqdm(mount_ids, desc=\"Mounts\"):\n",
    "    sub = df[df[\"mount_id\"] == mid].copy().set_index(\"date\").sort_index()\n",
    "    if sub.shape[0] == 0:\n",
    "        continue\n",
    "\n",
    "    # Reindex to a weekly Monday frequency between first and last data point to create consistent lags\n",
    "    start = sub.index.min()\n",
    "    end = sub.index.max()\n",
    "    weekly_idx = pd.date_range(start=start, end=end, freq=\"W-MON\")\n",
    "    sub = sub.reindex(weekly_idx)\n",
    "    # keep Year and week (recompute from index)\n",
    "    sub[\"year_iso\"] = sub.index.isocalendar().year\n",
    "    sub[\"week_iso\"] = sub.index.isocalendar().week\n",
    "\n",
    "    # Forward/backfill the mount_id column\n",
    "    sub[\"mount_id\"] = mid\n",
    "\n",
    "    # Build lag features for each target\n",
    "    for t in targets:\n",
    "        for lag in range(1, LAGS+1):\n",
    "            sub[f\"{t}_lag{lag}\"] = sub[t].shift(lag)\n",
    "\n",
    "    # Feature columns: week, year, and lag columns\n",
    "    feature_cols = [\"week_iso\", \"year_iso\"]\n",
    "    for t in targets:\n",
    "        for lag in range(1, LAGS+1):\n",
    "            feature_cols.append(f\"{t}_lag{lag}\")\n",
    "\n",
    "    # Training set: rows where target is not null and all lag features exist (not-null)\n",
    "    # We'll train one model per target using the same feature set (lags of all targets can help)\n",
    "    trained_models = {}\n",
    "    for target in targets:\n",
    "        train_mask = sub[target].notna()\n",
    "        for lag in range(1, LAGS+1):\n",
    "            train_mask &= sub[f\"{target}_lag{lag}\"].notna()\n",
    "        # Also require at least some rows\n",
    "        train_df = sub[train_mask].dropna(subset=feature_cols + [target])\n",
    "        if train_df.shape[0] >= MIN_ROWS_TO_TRAIN:\n",
    "            X = train_df[feature_cols].values\n",
    "            y = train_df[target].values\n",
    "            # fit RandomForestRegressor\n",
    "            model = RandomForestRegressor(n_estimators=100, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "            model.fit(X, y)\n",
    "            trained_models[target] = model\n",
    "        else:\n",
    "            trained_models[target] = None  # will fallback to weekly mean\n",
    "\n",
    "    # Prepare the lag buffer for iterative forecasting: use the most recent available values\n",
    "    last_row = sub.iloc[-1]\n",
    "    # Build an array of last known lags for each target (lag1..lagLAGS)\n",
    "    lag_buffer = {}\n",
    "    for t in targets:\n",
    "        buffer_vals = []\n",
    "        # collect last LAGS values if available in the reindexed sub\n",
    "        for lag in range(1, LAGS+1):\n",
    "            # the value at -lag index relative to last valid index\n",
    "            val = sub[t].shift(lag).iloc[-1]\n",
    "            if pd.isna(val):\n",
    "                # try to fallback to per-week mean for the corresponding ISO week (last known week - lag)\n",
    "                wk_index = (last_row[\"week_iso\"] - lag) % 52\n",
    "                wk_index = wk_index if wk_index != 0 else 52\n",
    "                row_mean = hist_week_mean[(hist_week_mean[\"mount_id\"] == mid) & (hist_week_mean[\"week\"] == wk_index)]\n",
    "                if row_mean.shape[0] > 0:\n",
    "                    val = float(row_mean[t].iloc[0])\n",
    "                else:\n",
    "                    val = sub[t].mean() if sub[t].dropna().shape[0] > 0 else 0.0\n",
    "            buffer_vals.append(float(val))\n",
    "        lag_buffer[t] = buffer_vals  # lag_buffer[t][0] is lag1 (most recent), [1] is lag2, ...\n",
    "\n",
    "    # Iteratively predict weeks 1..15 of 2026\n",
    "    # We'll iterate predictions: for each step, create feature vector = (week_iso, year_iso, all lag features)\n",
    "    for wk in FORECAST_WEEKS:\n",
    "        # compute current iso date for forecasting week\n",
    "        try:\n",
    "            wk_date = pd.to_datetime(date.fromisocalendar(FORECAST_YEAR, wk, 1))\n",
    "            wk_iso_week = wk\n",
    "            wk_iso_year = FORECAST_YEAR\n",
    "        except Exception:\n",
    "            wk_date = pd.NaT\n",
    "            wk_iso_week = wk\n",
    "            wk_iso_year = FORECAST_YEAR\n",
    "\n",
    "        preds_step = {}\n",
    "        for target in targets:\n",
    "            model = trained_models.get(target)\n",
    "            # build feature vector: week_iso, year_iso, then lag features for each target in same order\n",
    "            feat = [wk_iso_week, wk_iso_year]\n",
    "            # append lag features for all targets (we include cross-target lags)\n",
    "            for t in targets:\n",
    "                # use lag_buffer[t] in order lag1..lagLAGS\n",
    "                feat.extend(lag_buffer[t])\n",
    "            feat_arr = np.array(feat).reshape(1, -1)\n",
    "\n",
    "            if model is not None:\n",
    "                pred_val = float(model.predict(feat_arr)[0])\n",
    "            else:\n",
    "                # fallback: use historical mean for this mount_id and week\n",
    "                row_mean = hist_week_mean[(hist_week_mean[\"mount_id\"] == mid) & (hist_week_mean[\"week\"] == wk_iso_week)]\n",
    "                if row_mean.shape[0] > 0:\n",
    "                    pred_val = float(row_mean[target].iloc[0])\n",
    "                else:\n",
    "                    # final fallback: use overall mean of the target for this mount\n",
    "                    pred_val = float(sub[target].dropna().mean()) if sub[target].dropna().shape[0] > 0 else 0.0\n",
    "\n",
    "            preds_step[target] = pred_val\n",
    "\n",
    "        # append predicted values to results\n",
    "        results.append({\n",
    "            \"mount_id\": mid,\n",
    "            \"year\": FORECAST_YEAR,\n",
    "            \"week\": wk,\n",
    "            \"date\": wk_date,\n",
    "            \"max_temp\": round(preds_step[\"max_temp\"], 3),\n",
    "            \"min_temp\": round(preds_step[\"min_temp\"], 3),\n",
    "            \"rain\": round(preds_step[\"rain\"], 3)\n",
    "        })\n",
    "\n",
    "        # update lag_buffer by shifting and inserting the newest predictions as lag1\n",
    "        for t in targets:\n",
    "            # insert pred at front, drop oldest\n",
    "            lag_buffer[t] = [preds_step[t]] + lag_buffer[t][:LAGS-1]\n",
    "\n",
    "# Put results into DataFrame\n",
    "forecast_df = pd.DataFrame(results)\n",
    "forecast_df = forecast_df[[\"mount_id\",\"year\",\"week\",\"date\",\"max_temp\",\"min_temp\",\"rain\"]]\n",
    "forecast_df = forecast_df.sort_values([\"mount_id\",\"week\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7984ab15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved forecast to: forecast_2026_wks1_15_sklearn.csv\n"
     ]
    }
   ],
   "source": [
    "# Save and show\n",
    "forecast_df.to_csv(OUT_CSV, index=False)\n",
    "pd.set_option(\"display.max_rows\", 300)\n",
    "print(f\"\\nSaved forecast to: {OUT_CSV}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
